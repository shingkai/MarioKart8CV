{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Data transformations (96x96 resizing)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),            # Resize to 96x96 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset (without splitting into train/val yet)\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train'\n",
    "# data_dir = '/home/itsgrimetime/code/MarioKart8CV/items'\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))   # 80% training\n",
    "val_size = len(full_dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "# Load MobileNetV3-large pre-trained model\n",
    "model = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "# Move model to the GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Fine-tune the model\n",
    "model = train_model(model, criterion, optimizer, dataloaders, num_epochs=5)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), '../models/position_classifier_mobilenetv3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "classes = ['00','01',\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the fine-tuned MobileNetV3 model\n",
    "num_classes = len(classes)  # Change this based on your number of classes\n",
    "model = models.mobilenet_v3_large(pretrained=False)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "model.load_state_dict(torch.load('../models/position_classifier_mobilenetv3.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transform for inference (96x96 resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((96, 96)),  # Resize to 96x96 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to run inference on a cv2 frame\n",
    "def predict_frame(frame):\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Run the model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/donut_plains/p1_position/0/002801.png'\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_class = predict_frame(frame)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train/10/008809.png'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10.png'\n",
    "template = cv2.imread(template_path)\n",
    "\n",
    "mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10_mask.png'\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_template = cv2.bitwise_and(template, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_template, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the histogram for each color channel (B, G, R)\n",
    "hist_b = cv2.calcHist([masked_img], [0], None, [256], [10, 256])\n",
    "hist_g = cv2.calcHist([masked_img], [1], None, [256], [10, 256])\n",
    "hist_r = cv2.calcHist([masked_img], [2], None, [256], [10, 256])\n",
    "\n",
    "\n",
    "\n",
    "# Compare histograms between two images\n",
    "hist_b2 = cv2.calcHist([masked_template], [0], None, [256], [10, 256])\n",
    "hist_g2 = cv2.calcHist([masked_template], [1], None, [256], [10, 256])\n",
    "hist_r2 = cv2.calcHist([masked_template], [2], None, [256], [10, 256])\n",
    "\n",
    "# Use correlation or other similarity measures\n",
    "b_sim = cv2.compareHist(hist_b, hist_b2, cv2.HISTCMP_CORREL)\n",
    "g_sim = cv2.compareHist(hist_g, hist_g2, cv2.HISTCMP_CORREL)\n",
    "r_sim = cv2.compareHist(hist_r, hist_r2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "print(f\"Similarity B: {b_sim}, G: {g_sim}, R: {r_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train/10/008809.png'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10.png'\n",
    "template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/01.png'\n",
    "template = cv2.imread(template_path)\n",
    "\n",
    "# mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10_mask.png'\n",
    "mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/01_mask.png'\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_template = cv2.bitwise_and(template, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_template, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the histogram for each color channel (B, G, R)\n",
    "hist_b = cv2.calcHist([masked_img], [0], None, [256], [10, 256])\n",
    "hist_g = cv2.calcHist([masked_img], [1], None, [256], [10, 256])\n",
    "hist_r = cv2.calcHist([masked_img], [2], None, [256], [10, 256])\n",
    "\n",
    "\n",
    "\n",
    "# Compare histograms between two images\n",
    "hist_b2 = cv2.calcHist([masked_template], [0], None, [256], [10, 256])\n",
    "hist_g2 = cv2.calcHist([masked_template], [1], None, [256], [10, 256])\n",
    "hist_r2 = cv2.calcHist([masked_template], [2], None, [256], [10, 256])\n",
    "\n",
    "# Use correlation or other similarity measures\n",
    "b_sim = cv2.compareHist(hist_b, hist_b2, cv2.HISTCMP_CORREL)\n",
    "g_sim = cv2.compareHist(hist_g, hist_g2, cv2.HISTCMP_CORREL)\n",
    "r_sim = cv2.compareHist(hist_r, hist_r2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "print(f\"Similarity B: {b_sim}, G: {g_sim}, R: {r_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train/10/008809.png'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10.png'\n",
    "template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/07.png'\n",
    "template = cv2.imread(template_path)\n",
    "\n",
    "# mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10_mask.png'\n",
    "mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/07_mask.png'\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_template = cv2.bitwise_and(template, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_template, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the histogram for each color channel (B, G, R)\n",
    "hist_b = cv2.calcHist([masked_img], [0], None, [256], [10, 256])\n",
    "hist_g = cv2.calcHist([masked_img], [1], None, [256], [10, 256])\n",
    "hist_r = cv2.calcHist([masked_img], [2], None, [256], [10, 256])\n",
    "\n",
    "\n",
    "\n",
    "# Compare histograms between two images\n",
    "hist_b2 = cv2.calcHist([masked_template], [0], None, [256], [10, 256])\n",
    "hist_g2 = cv2.calcHist([masked_template], [1], None, [256], [10, 256])\n",
    "hist_r2 = cv2.calcHist([masked_template], [2], None, [256], [10, 256])\n",
    "\n",
    "# Use correlation or other similarity measures\n",
    "b_sim = cv2.compareHist(hist_b, hist_b2, cv2.HISTCMP_CORREL)\n",
    "g_sim = cv2.compareHist(hist_g, hist_g2, cv2.HISTCMP_CORREL)\n",
    "r_sim = cv2.compareHist(hist_r, hist_r2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "print(f\"Similarity B: {b_sim}, G: {g_sim}, R: {r_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train/07/001606.png'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10.png'\n",
    "template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/07.png'\n",
    "template = cv2.imread(template_path)\n",
    "\n",
    "# mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10_mask.png'\n",
    "mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/07_mask.png'\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "masked_template = cv2.bitwise_and(template, mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(masked_template, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the histogram for each color channel (B, G, R)\n",
    "hist_b = cv2.calcHist([masked_img], [0], None, [256], [10, 256])\n",
    "hist_g = cv2.calcHist([masked_img], [1], None, [256], [10, 256])\n",
    "hist_r = cv2.calcHist([masked_img], [2], None, [256], [10, 256])\n",
    "\n",
    "\n",
    "\n",
    "# Compare histograms between two images\n",
    "hist_b2 = cv2.calcHist([masked_template], [0], None, [256], [10, 256])\n",
    "hist_g2 = cv2.calcHist([masked_template], [1], None, [256], [10, 256])\n",
    "hist_r2 = cv2.calcHist([masked_template], [2], None, [256], [10, 256])\n",
    "\n",
    "# Use correlation or other similarity measures\n",
    "b_sim = cv2.compareHist(hist_b, hist_b2, cv2.HISTCMP_CORREL)\n",
    "g_sim = cv2.compareHist(hist_g, hist_g2, cv2.HISTCMP_CORREL)\n",
    "r_sim = cv2.compareHist(hist_r, hist_r2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "print(f\"Similarity B: {b_sim}, G: {g_sim}, R: {r_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/p1/01.png'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# template_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10.png'\n",
    "template_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/p2/01.png'\n",
    "template = cv2.imread(template_path)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "alpha = 2.0\n",
    "beta = 0\n",
    "\n",
    "boosted = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "boosted = cv2.convertScaleAbs(boosted, alpha=alpha, beta=beta)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the sharpening kernel \n",
    "kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) \n",
    "  \n",
    "# Sharpen the image \n",
    "sharpened_image = cv2.filter2D(boosted, -1, kernel) \n",
    "  \n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "sharpened_image2 = cv2.Laplacian(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB), cv2.CV_64F) \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sharpened_image2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "base_path = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/p2/'\n",
    "\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith('.png') and not file.endswith('mask.png'):\n",
    "\n",
    "        img = cv2.imread(os.path.join(base_path, file), 0)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        alpha = 1.5\n",
    "        beta = 0\n",
    "        boosted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # sharpened = cv2.Laplacian(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB), cv2.CV_64F)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(sharpened)\n",
    "\n",
    "        blurred = cv2.GaussianBlur(boosted, (5, 5), 1.5)\n",
    "        canny = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        mask = cv2.imread('/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/10_tight_mask.png',0)\n",
    "        masked_canny = cv2.bitwise_and(canny, mask)\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(masked_canny, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('/Users/shingkai/code/personal-projects/mk8/training_data/positions/train/04/002985.png',0)\n",
    "boosted = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "blurred = cv2.GaussianBlur(boosted, (5, 5), 1.5)\n",
    "canny = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "mask_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/position/edges/'\n",
    "\n",
    "min_error = None\n",
    "best_mask = None\n",
    "\n",
    "for file in os.listdir(mask_path):\n",
    "    if file.endswith('mask.png'):\n",
    "        mask = cv2.imread(os.path.join(mask_path, file),0)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        masked_canny = cv2.bitwise_and(canny, mask)\n",
    "\n",
    "        error = np.sum(masked_canny)\n",
    "        if min_error == None or min_error > error:\n",
    "            min_error = error\n",
    "            best_mask = file\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(masked_canny, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"total pixel value error: {np.sum(masked_canny)}\")\n",
    "        # print(f\"total pixel value error: {np.sum(masked_canny)}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best mask: {best_mask} with error: {min_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
