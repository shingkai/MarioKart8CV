{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/001825.png')\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Item(int, Enum):\n",
    "    BANANA = 1\n",
    "    TRIPLE_BANANA = 2\n",
    "    GREEN_SHELL = 3\n",
    "    TRIPLE_GREEN_SHELL = 4\n",
    "    RED_SHELL = 5\n",
    "    TRIPLE_RED_SHELL = 6\n",
    "    BLUE_SHELL = 7\n",
    "    BOB_OMB = 8\n",
    "    MUSHROOM = 9\n",
    "    TRIPLE_MUSHROOM = 10\n",
    "    GOLDEN_MUSHROOM = 11\n",
    "    BULLET_BILL = 12\n",
    "    BLOOPER = 13\n",
    "    LIGHTNING = 14\n",
    "    STAR = 15\n",
    "    FIRE_FLOWER = 16\n",
    "    BOOMERANG = 17\n",
    "    PIRANHA_PLANT = 18\n",
    "    SUPER_HORN = 19\n",
    "    CRAZY_EIGHT = 20\n",
    "    COIN = 21\n",
    "    FEATHER = 22\n",
    "    BOO = 23\n",
    "    NONE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN_SHELL : {[(3510,4002)]}\n",
    "RED_SHELL : {[(1825,1955)]}\n",
    "COIN : {[(2693,2860),(3443,3483)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_images(folder_path):\n",
    "    images = []\n",
    "    file_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = Image.open(file_path).convert('RGB')\n",
    "                img = img.resize((100, 100))  # Resize for consistency\n",
    "                images.append(img)\n",
    "                file_paths.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "    return images, file_paths\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hist = img.histogram()\n",
    "        features.append(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "def cluster_images(folder_path, n_clusters):\n",
    "    # Load images\n",
    "    print(\"Loading images...\")\n",
    "    images, file_paths = load_images(folder_path)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features...\")\n",
    "    features = extract_features(images)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    print(\"Clustering images...\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(normalized_features)\n",
    "    \n",
    "    # Organize images into clusters\n",
    "    clusters = {i: [] for i in range(n_clusters)}\n",
    "    for file_path, label in zip(file_paths, cluster_labels):\n",
    "        clusters[label].append(file_path)\n",
    "    \n",
    "    # Print results\n",
    "    for cluster, files in clusters.items():\n",
    "        print(f\"Cluster {cluster}: {len(files)} images\")\n",
    "        # Optionally, you can print file names or move files to cluster-specific folders here\n",
    "    \n",
    "    return clusters\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/\"\n",
    "n_clusters = 50\n",
    "clustered_images = cluster_images(folder_path, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in clustered_images[2][:5]:\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16, 64))\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(50):\n",
    "    for j in range(10):\n",
    "        plt.subplot(50,10,i*10+j+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.cvtColor(cv2.imread(clustered_images[i][j]), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# # Check if GPU is available (either cuda for nvidia or mps for apple silicon)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else  torch.device(\"cpu\"))\n",
    "\n",
    "\n",
    "# Define transformations for the dataset (same for train and validation initially)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set the directory path where the dataset is stored (single directory with subdirectories for each class)\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/items'\n",
    "# data_dir = '/home/itsgrimetime/code/MarioKart8CV/items'\n",
    "\n",
    "# Load the dataset from the directory\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
    "\n",
    "# Split the dataset into train and validation sets (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders for train and validation sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dictionary to hold the dataloaders\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "# Sizes of the datasets\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Class names (same as subdirectory names)\n",
    "class_names = full_dataset.classes\n",
    "print(f\"class names: {class_names}\")\n",
    "\n",
    "# Load the pretrained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the network except the final classifier layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit our dataset (assuming the number of classes is determined by the dataset)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Learning rate scheduler to decrease learning rate by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Track loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Adjust learning rate\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model if it has improved\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 25\n",
    "best_model = train_model(model, criterion, optimizer, scheduler, num_epochs)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(best_model.state_dict(), 'best_model_vgg16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ['1','3','5','9','16','21','None']\n",
    "\n",
    "class_names = ['1', '16', '21', '3', '5', '9', 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# # Check if GPU is available (either cuda for nvidia or mps for apple silicon)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else  torch.device(\"cpu\"))\n",
    "\n",
    "\n",
    "# Load the model architecture\n",
    "model = models.vgg16(pretrained=False)\n",
    "num_features = model.classifier[6].in_features\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your model\n",
    "model.classifier[6] = torch.nn.Linear(num_features, len(class_names))  # class_names should have the number of classes in your dataset\n",
    "\n",
    "# Load the saved weights\n",
    "\n",
    "model.load_state_dict(torch.load('/Users/shingkai/code/personal-projects/mk8/models/item_classifier_vgg16.pth', map_location=device))\n",
    "# model.load_state_dict(torch.load('/home/itsgrimetime/code/MarioKart8CV/notebooks/best_model_vgg16.pth', map_location=device))\n",
    "\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the appropriate device (MPS or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the transformation to be applied to the input image (same as used during training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array (cv2) to PIL image\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(frame):\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img = preprocess(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Add batch dimension (PyTorch models expect a batch of images)\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Move the image to the same device as the model (MPS or CPU)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    # Turn off gradients for inference (faster and reduces memory usage)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "    \n",
    "    # Get the predicted class (with the highest score)\n",
    "    _, predicted_class = torch.max(outputs, 1)\n",
    "    \n",
    "    # Map the predicted class index to the class name\n",
    "    predicted_class_name = class_names[predicted_class.item()]\n",
    "    \n",
    "    return predicted_class_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Example of running inference\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/020094.png'\n",
    "# image_path = '/home/itsgrimetime/code/MarioKart8CV/race_videoss/training/item1/Player.P1/000922.png'\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_label = predict_image(frame)\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/026030.png'\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_label = predict_image(frame)\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/025855.png'\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_label = predict_image(frame)\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/029638.png'\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_label = predict_image(frame)\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNeXt-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "num_classes = 7  # Change this to the number of classes in your dataset\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "val_split = 0.2  # 20% of the data will be used for validation\n",
    "\n",
    "# Define the data transforms for training and validation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/items'  # Update this to your dataset path\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# Calculate the sizes for training and validation\n",
    "num_val_samples = int(val_split * len(dataset))\n",
    "num_train_samples = len(dataset) - num_val_samples\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset, val_dataset = random_split(dataset, [num_train_samples, num_val_samples])\n",
    "\n",
    "# Create the data loaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Get the number of classes\n",
    "class_names = dataset.classes\n",
    "print(f\"class names: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load the ResNeXt-50 model, pretrained on ImageNet\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in your dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the device (MPS, CUDA, or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Calculate the loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model if it has better accuracy\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "best_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Save the best model weights\n",
    "torch.save(best_model.state_dict(), 'item_classifier_resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "classes = ['01', '02', '03', '04', '05', '07', '09', '10', '11', '12', '13', '15', '16', '18', '19', '21', '23', '24']\n",
    "\n",
    "# # Check if GPU is available (either cuda for nvidia or mps for apple silicon)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else  torch.device(\"cpu\"))\n",
    "\n",
    "\n",
    "# Load the model architecture\n",
    "# model = models.resnext50_32x4d(pretrained=False)\n",
    "model = models.resnet18(pretrained=True)\n",
    " # Adjust final layer to match output classes\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, len(class_names)) \n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load('/Users/shingkai/code/personal-projects/mk8/models/item_classifier_resnet18.pth', map_location=device))\n",
    "# model.load_state_dict(torch.load('/home/itsgrimetime/code/MarioKart8CV/notebooks/item_classifier_resnet18.pth', map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the appropriate device (MPS or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the transformation to be applied to the input image (same as used during training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array (cv2) to PIL image\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_from_frame(frame):\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img = preprocess(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Add batch dimension (PyTorch models expect a batch of images)\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Move the image to the same device as the model (MPS or CPU)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    # Turn off gradients for inference (faster and reduces memory usage)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "    \n",
    "    # Get the predicted class (with the highest score)\n",
    "    _, predicted_class = torch.max(outputs, 1)\n",
    "    \n",
    "    # Map the predicted class index to the class name\n",
    "    predicted_class_name = class_names[predicted_class.item()]\n",
    "    \n",
    "    return predicted_class_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "classes = ['01', '02', '03', '04', '05', '07', '09', '10', '11', '12', '13', '15', '16', '18', '19', '21', '23', '24']\n",
    "\n",
    "# Example of running inference\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/020094.png'\n",
    "# image_path = '/home/itsgrimetime/code/MarioKart8CV/race_videoss/training/item1/Player.P1/000922.png'\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_label = predict_from_frame(frame)\n",
    "\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Set up parameters\n",
    "img_width, img_height = 112, 112  # SqueezeNet default input size\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/items'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else  torch.device(\"cpu\"))\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images = self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(self.data_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                img_path = os.path.join(cls_dir, img_name)\n",
    "                images.append((img_path, self.class_to_idx[cls_name]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_width, img_height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = CustomDataset(data_dir, transform=data_transforms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "# Modify the classifier\n",
    "model.classifier[1] = nn.Conv2d(512, len(dataset.classes), kernel_size=(1,1), stride=(1,1))\n",
    "model.num_classes = len(dataset.classes)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'squeezenet_pytorch.pth')\n",
    "\n",
    "print(\"Training completed. Model saved as 'squeezenet_pytorch.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['01', '02', '03', '04', '05', '07', '09', '10', '11', '12', '13', '15', '16', '18', '19', '21', '23', '24']\n",
    "\n",
    "# Set up parameters\n",
    "img_width, img_height = 112, 112  # SqueezeNet default input size\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else  torch.device(\"cpu\"))\n",
    "\n",
    "# Load the pre-trained SqueezeNet model architecture\n",
    "model = models.squeezenet1_1(pretrained=False)\n",
    "\n",
    "# Modify the classifier to match your number of classes\n",
    "num_classes = len(classes)  # Replace with the number of classes in your dataset\n",
    "model.classifier[1] = torch.nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "model.num_classes = num_classes\n",
    "\n",
    "# Load the saved state dict\n",
    "model.load_state_dict(torch.load('squeezenet_pytorch.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation for input images\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((img_width, img_height)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to predict on a single image\n",
    "def predict_image(image_path, model, transform):\n",
    "    image = cv2.imread(image_path)\n",
    "    predict_frame(image, model, transform)\n",
    "\n",
    "\n",
    "# Function to predict on a cv2 frame\n",
    "def predict_frame(frame, model=model, preprocess=preprocess):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "        confidence = probabilities[predicted_class].item()\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "classes = ['01', '02', '03', '04', '05', '07', '09', '10', '11', '12', '13', '15', '16', '18', '19', '21', '23', '24']\n",
    "\n",
    "# Example of running inference\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/020094.png'\n",
    "\n",
    "\n",
    "# image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/026030.png'\n",
    "# image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_first_item/0/025855.png'\n",
    "\n",
    "\n",
    "# image_path = '/home/itsgrimetime/code/MarioKart8CV/race_videoss/training/item1/Player.P1/000922.png'\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "prediction, confidence = predict_frame(frame)\n",
    "predicted_label = classes[prediction]\n",
    "\n",
    "print(f'The predicted label for the image is: {predicted_label} ({confidence:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "img_width, img_height = 112, 112\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "val_split = 0.2  # 20% of the data will be used for validation\n",
    "\n",
    "# Define the data transforms for training and validation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_width, img_height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/items'  # Update this to your dataset path\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# Calculate the sizes for training and validation\n",
    "num_val_samples = int(val_split * len(dataset))\n",
    "num_train_samples = len(dataset) - num_val_samples\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset, val_dataset = random_split(dataset, [num_train_samples, num_val_samples])\n",
    "\n",
    "# Create the data loaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Get the number of classes\n",
    "class_names = dataset.classes\n",
    "print(f\"class names: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Load the ResNeXt-50 model, pretrained on ImageNet\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# model = models.resnet18(pretrained=True)\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in your dataset\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Modify the classifier\n",
    "model.classifier[1] = nn.Conv2d(512, len(dataset.classes), kernel_size=(1,1), stride=(1,1))\n",
    "model.num_classes = len(dataset.classes)\n",
    "\n",
    "# Move the model to the device (MPS, CUDA, or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Calculate the loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model if it has better accuracy\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "best_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Save the best model weights\n",
    "torch.save(best_model.state_dict(), 'item_classifier_squeezenet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Data transformations (96x96 resizing)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),            # Resize to 96x96 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset (without splitting into train/val yet)\n",
    "data_dir = '/Users/shingkai/code/personal-projects/mk8/training_data/positions/train'\n",
    "# data_dir = '/home/itsgrimetime/code/MarioKart8CV/items'\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))   # 80% training\n",
    "val_size = len(full_dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "# Load MobileNetV3-large pre-trained model\n",
    "model = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "# Move model to the GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Fine-tune the model\n",
    "model = train_model(model, criterion, optimizer, dataloaders, num_epochs=5)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), '../models/position_classifier_mobilenetv3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "classes = ['00','01',\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the fine-tuned MobileNetV3 model\n",
    "num_classes = len(classes)  # Change this based on your number of classes\n",
    "model = models.mobilenet_v3_large(pretrained=False)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "model.load_state_dict(torch.load('../models/position_classifier_mobilenetv3.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transform for inference (96x96 resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((96, 96)),  # Resize to 96x96 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to run inference on a cv2 frame\n",
    "def predict_frame(frame):\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Run the model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/donut_plains/p1_position/0/002801.png'\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "predicted_class = predict_frame(frame)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
