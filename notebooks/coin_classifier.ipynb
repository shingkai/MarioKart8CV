{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "base_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/coins/'\n",
    "write_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/coins/edges/'\n",
    "\n",
    "for i in range(1,11):\n",
    "    img = cv2.imread(os.path.join(base_path, f\"{i:02}.png\"), 0)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "    img = cv2.resize(img, (width * 4, height * 4))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    boosted = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    canny = cv2.Canny(boosted, threshold1=50, threshold2=150)\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # cv2.imwrite(os.path.join(write_path, f\"{i:02}.png\"), canny)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "base_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/coins/'\n",
    "write_path = '/Users/shingkai/code/personal-projects/mk8/MarioKart8CV/templates/coins/edges/'\n",
    "\n",
    "\n",
    "\n",
    "# formatted as (x, y)\n",
    "magic_pixels = [\n",
    "    (6, 10), # left 0-indicator\n",
    "    (13, 10), # left 1-indicator\n",
    "]\n",
    "\n",
    "for i in range(9,11):\n",
    "    print(f\"==== {i:02} ====\")\n",
    "    img = cv2.imread(os.path.join(base_path, f\"{i:02}.png\"), 0)\n",
    "\n",
    "    # height, width = img.shape[:2]\n",
    "    # img = cv2.resize(img, (width * 4, height * 4))\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    boosted = cv2.convertScaleAbs(img, alpha=3.0, beta=-100)\n",
    "\n",
    "    for (x, y) in magic_pixels:\n",
    "        print(f\"{boosted[y, x]}\")\n",
    "        cv2.circle(boosted, (x, y), 1, (128, 128, 128), thickness=-1)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # canny = cv2.Canny(boosted, threshold1=50, threshold2=150)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # cv2.imwrite(os.path.join(write_path, f\"{i:02}.png\"), canny)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_coins/0/020877.png'\n",
    "\n",
    "img = cv2.imread(img_path, 0)\n",
    "boosted = cv2.convertScaleAbs(img, alpha=3.0, beta=-100)\n",
    "plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def boost_orange(image):\n",
    "    # Convert the image from BGR to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_orange = np.array([20, 200, 200])\n",
    "    upper_orange = np.array([40, 255, 255])\n",
    "    mask = cv2.inRange(hsv_image, lower_orange, upper_orange)\n",
    "\n",
    "    # Increase the brightness for the selected areas (increase the V channel in HSV)\n",
    "    # First, split the HSV channels\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "    # Boost the brightness (V channel) for the in-range areas\n",
    "    v[mask > 0] = np.clip(v[mask > 0] + 50, 0, 255)  # Increase brightness by 50, clipped to 255\n",
    "\n",
    "    # Merge back the modified HSV channels\n",
    "    boosted_hsv = cv2.merge([h, s, v])\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "    boosted_image = cv2.cvtColor(boosted_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return boosted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_coins/0/004591.png'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "boosted = boost_orange(image)\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(boosted, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_hue_saturation(image, hue_range, saturation_range):\n",
    "    \"\"\"Extracts regions matching the given hue and saturation ranges.\"\"\"\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for hue and saturation\n",
    "    lower_bound = np.array([hue_range[0], saturation_range[0], 0])\n",
    "    upper_bound = np.array([hue_range[1], saturation_range[1], 255])\n",
    "\n",
    "    # Create a mask using the inRange function\n",
    "    mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "\n",
    "    # Define the kernel size for dilation (the larger the kernel, the more the mask will expand)\n",
    "    kernel_size = 2  # You can increase this size to expand more\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "\n",
    "    # Apply dilation\n",
    "    expanded_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    # Create a white pixel (255, 255, 255)\n",
    "    white = np.array([255, 255, 255], dtype=np.uint8)\n",
    "    # Change pixels to white where the mask is non-zero\n",
    "    image[expanded_mask != 0] = white\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_coins/0/004591.png'\n",
    "image_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p2_coins/0/029837.png'\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Define the desired hue and saturation ranges\n",
    "hue_range = (0, 25)  # Example: orange hue range\n",
    "saturation_range = (200, 255)  # Example: high saturation\n",
    "\n",
    "# Extract the matching regions\n",
    "result = extract_hue_saturation(image, hue_range, saturation_range)\n",
    "\n",
    "# Display the result\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_coins/0/020877.png'\n",
    "# img_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p2_coins/0/029837.png'\n",
    "img_path = '/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p2_coins/0/022118.png'\n",
    "\n",
    "img = cv2.imread(img_path, 0)\n",
    "\n",
    "threshold = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(threshold, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import abstractmethod, ABC\n",
    "import logging\n",
    "\n",
    "import cv2\n",
    "from cv2.typing import MatLike\n",
    "import numpy as np\n",
    "\n",
    "from mk8cv.data.state import Player, Stat\n",
    "from mk8cv.processing.aois import CROP_COORDS\n",
    "\n",
    "\n",
    "class LapClassifier(ABC):\n",
    "    def __init__(self) -> None:\n",
    "        self._model = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self, model_path: str = None) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _predict(self, frame: MatLike) -> tuple[int, int]:\n",
    "        pass\n",
    "\n",
    "    def extract_laps(self, frame: MatLike, player: Player) -> tuple[int, int]:\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        lap_num_coords = CROP_COORDS[player][Stat.LAP_NUM]\n",
    "        race_laps_coords = CROP_COORDS[player][Stat.RACE_LAPS]\n",
    "\n",
    "        lap_num = self._predict(frame=frame[round(height * lap_num_coords[2]): round(height * lap_num_coords[3]), round(width * lap_num_coords[0]): round(width * lap_num_coords[1])])\n",
    "        race_laps = self._predict(frame=frame[round(height * race_laps_coords[2]): round(height * race_laps_coords[3]), round(width * race_laps_coords[0]): round(width * race_laps_coords[1])])\n",
    "\n",
    "        return lap_num, race_laps\n",
    "\n",
    "class SevenSegmentLapClassifier(LapClassifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def load(self, model_path: str = None):\n",
    "        pass\n",
    "\n",
    "    def _predict(self, frame: MatLike) -> tuple[int, int]:\n",
    "        result, visualization = self._recognize_seven_segment(frame)\n",
    "        return result\n",
    "\n",
    "    def _preprocess_image(self, image):\n",
    "        # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        # plt.title('Original Preprocess')\n",
    "        # image = cv2.resize(image, (65, 48))\n",
    "        image = cv2.resize(image, (27, 42))\n",
    "\n",
    "        blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        # plt.imshow(blurred)\n",
    "        # plt.title(\"blurred\")\n",
    "\n",
    "        # boosted = cv2.convertScaleAbs(blurred, alpha=1.5, beta=-100)\n",
    "        # plt.imshow(boosted)\n",
    "        # plt.title(\"boosted\")\n",
    "\n",
    "        gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR))\n",
    "        # plt.title('gray')\n",
    "\n",
    "        thresh = cv2.threshold(gray, 175, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        # plt.figure()\n",
    "        # plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR))\n",
    "        # plt.title(\"thresh\")\n",
    "\n",
    "        return thresh\n",
    "\n",
    "\n",
    "    def _extract_segments(self, preprocessed_image, original_image):\n",
    "        h, w = preprocessed_image.shape\n",
    "        cv2.imshow('preprocessed_image', preprocessed_image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        # Define relative positions for each segment's check point\n",
    "        # Format: (x1, y1, x2, y2) where 1 is for the first digit and 2 is for the second digit\n",
    "        segment_points = [\n",
    "            (0.7, 0.2),  # Top\n",
    "            (0.575, 0.35),  # Top-left\n",
    "            (0.825, 0.35),  # Top-right\n",
    "            (0.7, 0.5),  # Middle\n",
    "            (0.55, 0.67),  # Bottom-left\n",
    "            (0.785, 0.67),  # Bottom-right\n",
    "            (0.675, 0.775)  # Bottom\n",
    "        ]\n",
    "\n",
    "        segments = []  # List to store segments for both digits\n",
    "        visualization = original_image.copy()\n",
    "\n",
    "\n",
    "        for i, (x, y) in enumerate(segment_points):\n",
    "            # print(f\"{preprocessed_image[int(h * y), int(w * x)]}\")\n",
    "            # segment_value = 1 if preprocessed_image[int(h * y), int(w * x)] > 250 else 0\n",
    "            segment_area = preprocessed_image[int((h * y) - 1):int((h * y) + 1),\n",
    "                           int((w * x) - 1):int((w * x) + 1)]\n",
    "            segment_value = 1 if np.mean(segment_area) < 5 else 0\n",
    "            cv2.circle(visualization, (int(x * w), int(y * h)), 1, (0, 255, 0) if segment_value else (255, 0, 0), thickness=-1)\n",
    "            # print(f\"{preprocessed_image[int(h * y), int(w * x)]}\")\n",
    "\n",
    "            segments.append(segment_value)\n",
    "\n",
    "            # Visualization\n",
    "            color = (0, 255, 0) if segment_value else (0, 0, 255)\n",
    "\n",
    "        # return segments, visualization\n",
    "        return segments, preprocessed_image, visualization\n",
    "\n",
    "    def _decode_segments(self, segments):\n",
    "        segment_patterns = {\n",
    "            #    0  1  t  tl tr m  bl br b\n",
    "            (1, 1, 1, 0, 1, 1, 1): 0,\n",
    "            (0, 0, 1, 0, 0, 1, 0): 1,\n",
    "            (1, 0, 1, 1, 1, 0, 1): 2,\n",
    "            (1, 0, 1, 1, 0, 1, 1): 3,\n",
    "            (0, 1, 1, 1, 0, 1, 0): 4,\n",
    "            (1, 1, 0, 1, 0, 1, 1): 5,\n",
    "            (1, 1, 0, 1, 1, 1, 1): 6,\n",
    "            (1, 0, 1, 0, 0, 1, 0): 7,\n",
    "            (1, 1, 1, 1, 1, 1, 1): 8,\n",
    "            (1, 1, 1, 1, 0, 1, 1): 9,\n",
    "        }\n",
    "        result = segment_patterns.get(tuple(segments), -1)\n",
    "        # print(f'result: {result}')\n",
    "        return result\n",
    "\n",
    "    def _recognize_seven_segment(self, image):\n",
    "        preprocessed = self._preprocess_image(image)\n",
    "        segments, preprocessed, visualization = self._extract_segments(preprocessed, image)\n",
    "\n",
    "        # Convert preprocessed (grayscale) to BGR\n",
    "        preprocessed_bgr = cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Concatenate images horizontally\n",
    "        debug_output = cv2.resize(cv2.hconcat([preprocessed_bgr, visualization]), (0, 0), fx=4.0, fy=4.0)\n",
    "\n",
    "        # Display the concatenated image\n",
    "        cv2.imshow('Preprocessed | Visualization', debug_output)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        digit = self._decode_segments(segments)\n",
    "        recognized_number = digit\n",
    "\n",
    "        return recognized_number, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SevenSegmentLapClassifier()\n",
    "classifier.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_num_img_path = \"/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_lap/0/006800.png\"\n",
    "race_laps_img_path = \"/Users/shingkai/code/personal-projects/mk8/race_videos/training/mirror_flower_cup/p1_lap/0/006800.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
